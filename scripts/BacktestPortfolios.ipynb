{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance  as yf\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import joblib\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, shapiro,  gaussian_kde\n",
    "from scipy.integrate import quad\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data, period='5y'):\n",
    "    dfs = []\n",
    "    if isinstance(data, dict):\n",
    "        for name, ticker in data.items():\n",
    "            ticker_obj = yf.Ticker(ticker)\n",
    "            hist = ticker_obj.history(period=period)\n",
    "            hist.columns = [f\"{name}_{col}\" for col in hist.columns]  # Add prefix to the name\n",
    "            hist.index = pd.to_datetime(hist.index.map(lambda x: x.strftime('%Y-%m-%d')))\n",
    "            close_columns = [col for col in hist.columns if col.endswith('_Close')]\n",
    "            hist = hist[close_columns]\n",
    "            dfs.append(hist)\n",
    "    return dfs\n",
    "\n",
    "dicts = {#'commodities':commodities_dict,\n",
    "         #'b3_stocs': b3_stocks,\n",
    "         'SP500': sp500_dict,\n",
    "         #'NASDAC100':nasdaq_dict,\n",
    "         #'indexes': indexes_dict,\n",
    "         #'currencies': currencies_dict, \n",
    "         #'crypto': crypto_dict}\n",
    "        }\n",
    "\n",
    "# storedAssets = []\n",
    "for key, ticker in tqdm(dicts.items()):\n",
    "    assets = download_data(ticker)  # Baixa os dados\n",
    "    for asset in assets:\n",
    "        storedAssets.append(asset)\n",
    "assets = storedAssets.copy()\n",
    "joblib.dump(assets, 'portfolios.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('..', 'pkl', 'portfolios.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath\n",
    "assets = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bound = 2 * 252  # Define o limite mínimo de tamanho para os ativos\n",
    "assets = [asset[bound:] for asset in assets if len(asset) >= bound]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    \"\"\"\n",
    "    A class to manage investment portfolios.\n",
    "\n",
    "    Attributes:\n",
    "    - data (DataFrame): A DataFrame containing historical prices of assets.\n",
    "    - invested_capital (float): The amount of capital invested in the portfolio.\n",
    "    - window_size (int): The size of the window for processing data.\n",
    "    - chunk_dfs (list): A list of DataFrames representing data chunks.\n",
    "    - prices (np.array): An array containing the latest prices of assets.\n",
    "    - names (list): A list of asset names.\n",
    "    - dates (list): A list of last dates for each chunk.\n",
    "    - sharpe_weights (np.array): Optimal weights for maximum Sharpe ratio.\n",
    "    - min_risk_weights (np.array): Optimal weights for minimum risk.\n",
    "    - max_sharpe_control (list): Portfolio optimized for maximum Sharpe ratio with rebalancing.\n",
    "    - max_sharpe (list): Portfolio optimized for maximum Sharpe ratio without rebalancing.\n",
    "    - min_risk_control (list): Portfolio optimized for minimum risk with rebalancing.\n",
    "    - min_risk (list): Portfolio optimized for minimum risk without rebalancing.\n",
    "    - even_weights (list): Portfolio with even weights.\n",
    "    - smart_max_sharpe_control (list): Smartly rebalanced portfolio optimized for maximum Sharpe ratio.\n",
    "    - smart_max_sharpe (list): Smartly rebalanced portfolio optimized for maximum Sharpe ratio without rebalancing.\n",
    "    - smart_min_risk_control (list): Smartly rebalanced portfolio optimized for minimum risk.\n",
    "    - smart_min_risk (list): Smartly rebalanced portfolio optimized for minimum risk without rebalancing.\n",
    "    - smart_even_weights (list): Smartly rebalanced portfolio with even weights.\n",
    "    - portfolio_ROI (list): Evaluation of portfolios' portfolio_portfolio_portfolio_ROI considering each round of optimization and the final ROI.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, data, invested_capital = 100000,  window_size=30):\n",
    "        self.invested_capital = invested_capital\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        self.chunk_dfs = self.process_data(window_size)\n",
    "        self.prices = self.get_prices()\n",
    "        self.names = self.get_asset_name()\n",
    "        self.dates  = self.get_last_dates()\n",
    "        self.sharpe_weights, self.max_sharpe_risk  = self.get_opt_values()\n",
    "        self.min_risk_weights, self.min_risk = self.get_opt_values(objective = 'risk')\n",
    "        self.max_sharpe_control= self.dummy_balancer(method='sharpe_control')\n",
    "        self.max_sharpe = self.dummy_balancer(method = 'sharpe')\n",
    "        self.min_risk_control = self.dummy_balancer(method = 'risk_control')\n",
    "        self.min_risk = self.dummy_balancer(method = 'risk') \n",
    "        self.even_weights = self.dummy_balancer(method = 'even')\n",
    "        self.smart_max_sharpe_control = self.smart_balancer(method='sharpe_control')\n",
    "        self.smart_max_sharpe = self.smart_balancer(method = 'sharpe')\n",
    "        self.smart_min_risk_control = self.smart_balancer(method = 'risk_control')\n",
    "        self.smart_min_risk = self.smart_balancer(method = 'risk')\n",
    "        self.smart_even_weights = self.smart_balancer(method = 'even')\n",
    "        self.portfolio_ROI  = self.get_portfolio_ROI()\n",
    "    \n",
    "        self.plot_ROI = self.plot_ROI_over_time()\n",
    "    \n",
    "    \n",
    "    def process_data(self, window_size):    \n",
    "        \"\"\"\n",
    "        Processes data into chunks.portfolio_ROI\n",
    "\n",
    "        Parameters:\n",
    "        - window_size: Size of the window.\n",
    "\n",
    "        Returns:\n",
    "        - List of DataFrames representing data chunks.\n",
    "        \"\"\"\n",
    "        chunk_dfs = []\n",
    "        for i in range(0, len(self.data), window_size):\n",
    "            if i + window_size <= len(self.data):\n",
    "                chunk_df = self.data.iloc[i:i+window_size].copy()\n",
    "            else:\n",
    "                chunk_df = self.data.iloc[i:].copy()\n",
    "        \n",
    "            chunk_dfs.append(chunk_df)\n",
    "            \n",
    "        return chunk_dfs\n",
    "    \n",
    "    \n",
    "    def simulate_frontier(self, chunk_df, risk_free_rate=0, trading_days=252, simulations=10000, objective='sharpe'):\n",
    "        \"\"\"\n",
    "        Simulates optimal asset allocation based on the Sharpe ratio within a specified tolerance range,\n",
    "        and selects the one with the highest Sharpe ratio.\n",
    "\n",
    "        Parameters:\n",
    "        - chunk_df: DataFrame containing asset prices.\n",
    "        - risk_free_rate: Risk-free rate.\n",
    "        - trading_days: Number of trading days.\n",
    "        - simulations: Number of simulations.\n",
    "        - sharpe_tolerance: Tolerance range for the Sharpe ratio.\n",
    "        - objective: 'sharpe' or 'risk' to specify whether to maximize Sharpe ratio or minimize risk.\n",
    "\n",
    "        Returns:\n",
    "        - Numpy array representing optimal asset allocation with the highest Sharpe ratio or lowest positive standard deviation.\n",
    "        \"\"\"\n",
    "        max_sharpe_ratio = -np.inf\n",
    "        min_positive_sd = np.inf\n",
    "        optimal_weights = None\n",
    "        num_assets = len(chunk_df.columns)\n",
    "        simple_returns = chunk_df.pct_change().dropna().mean() * trading_days\n",
    "        cov_matrix = chunk_df.pct_change().dropna().cov() * trading_days\n",
    "\n",
    "        for _ in range(simulations):\n",
    "            weights = np.random.random(num_assets)\n",
    "            weights /= np.sum(weights)\n",
    "            returns = np.dot(weights, simple_returns)\n",
    "            var = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "            sd = np.sqrt(var)\n",
    "\n",
    "            if objective == 'sharpe':\n",
    "                sharpe_ratio = (returns - risk_free_rate) / sd\n",
    "                if sharpe_ratio > max_sharpe_ratio:\n",
    "                    max_sharpe_ratio = sharpe_ratio\n",
    "                    optimal_weights = weights\n",
    "            elif objective == 'risk':\n",
    "                if sd > 0 and sd < min_positive_sd:\n",
    "                    min_positive_sd = sd\n",
    "                    optimal_weights = weights\n",
    "                    \n",
    "            else:\n",
    "                raise ValueError(\"Objective must be either 'sharpe' or 'risk'.\")\n",
    "        \n",
    "        return optimal_weights, sd\n",
    "\n",
    "    def get_opt_values(self, lower_bound=0.00, upper_bound=1, objective='sharpe'):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate optimal portfolio weights for each chunk of data using mean-variance optimization.\n",
    "\n",
    "        Parameters:\n",
    "        lower_bound : float, optional\n",
    "            The minimum bound for the weights. Default is 0.00.\n",
    "        upper_bound : float, optional\n",
    "            The maximum bound for the weights. Default is 1.\n",
    "        objective : str, optional\n",
    "            The objective for optimization. Can be 'sharpe' for maximizing the Sharpe ratio\n",
    "            or 'min_volatility' for minimizing portfolio volatility. Default is 'sharpe'.\n",
    "        Returns:\n",
    "        np.array\n",
    "            A numpy array of optimal weights for each chunk of data.\n",
    "        \"\"\" \n",
    "        \n",
    "        opt_weights = []\n",
    "        pfl_risk = []\n",
    "        \n",
    "        for i, chunk_df in enumerate(self.chunk_dfs):\n",
    "            try: \n",
    "                mu = expected_returns.mean_historical_return(chunk_df)\n",
    "                S = risk_models.sample_cov(chunk_df)\n",
    "                ef = EfficientFrontier(mu, S, weight_bounds=(lower_bound, upper_bound))\n",
    "                if objective == 'sharpe':\n",
    "                    ef.max_sharpe(risk_free_rate=0)\n",
    "                else:\n",
    "                    ef.min_volatility()\n",
    "                cleaned_weights = ef.clean_weights()\n",
    "                weights = [weight for _, weight in cleaned_weights.items()]\n",
    "                \n",
    "\n",
    "                risk = ef.port_volatility()\n",
    "                opt_weights.append(weights)\n",
    "                pfl_risk.append(risk)\n",
    "\n",
    "            except Exception as e:\n",
    "                \n",
    "                #print(f\"Error calculating optimal weights for chunk {i} \\n Trying to simulate closest weights\")\n",
    "                if objective == 'sharpe':\n",
    "                    simulated_max_sharpe_w, simulated_max_sharpe_risk  = self.simulate_frontier(chunk_df, risk_free_rate=0, objective=objective)\n",
    "                    opt_weights.append(simulated_max_sharpe_w)\n",
    "                    pfl_risk.append(simulated_max_sharpe_risk)\n",
    "                else:\n",
    "                    simulated_lowest_risk_w, simulated_lowest_risk = self.simulate_frontier(chunk_df, objective=objective)\n",
    "                    opt_weights.append(simulated_lowest_risk_w)\n",
    "                    pfl_risk.append(simulated_lowest_risk)\n",
    " \n",
    "        optimal_weights = [weights for weights in opt_weights if weights is not None]\n",
    "        optimal_risk = [risk for risk in pfl_risk if risk is not None]\n",
    "        \n",
    "        return  np.array(optimal_weights),  np.array(optimal_risk)\n",
    "\n",
    "    def get_prices(self):\n",
    "        prices = []\n",
    "        for chunk_df in self.chunk_dfs:\n",
    "            last_values = chunk_df.iloc[-1].values\n",
    "            prices.append(last_values)\n",
    "        return np.array(prices)\n",
    "\n",
    "    def get_last_dates(self):\n",
    "        \"\"\"\n",
    "        Gets the last index for each chunk.\n",
    "\n",
    "        Returns:\n",
    "        - List of last indices for each chunk.\n",
    "        \"\"\"\n",
    "        last_indices = []\n",
    "        for chunk_df in self.chunk_dfs[1:]:\n",
    "            last_index = chunk_df.index[-1]\n",
    "            last_index_date_only = str(last_index).split()[0]\n",
    "            last_indices.append(last_index_date_only)\n",
    "        return last_indices\n",
    "\n",
    "    def get_asset_name(self, string ='_Close' ):\n",
    "        \"\"\"\n",
    "        Gets the names of assets.\n",
    "\n",
    "        Returns:\n",
    "        - List of asset names.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        df = self.chunk_dfs[0]\n",
    "        for column in df.columns:\n",
    "            if  string in column:\n",
    "                names.append(column.replace(string, ''))\n",
    "            else:\n",
    "                names.append(column)\n",
    "        return names\n",
    "\n",
    "\n",
    "    def smart_balancer(self, method='sharpe_control'):\n",
    "        prices = self.prices\n",
    "        if method == 'sharpe':\n",
    "            weights = self.sharpe_weights\n",
    "        elif method == 'risk':\n",
    "            weights = self.min_risk_weights\n",
    "        elif method == 'even':\n",
    "            weights = np.full_like(prices, 1 / prices.shape[1])\n",
    "        elif method == 'risk_control':\n",
    "            weights = np.full_like(prices, self.min_risk_weights[0])\n",
    "        else:\n",
    "            weights = np.full_like(prices, self.sharpe_weights[0])\n",
    "        \n",
    "        sold_all = np.zeros_like(prices)\n",
    "        funds = np.zeros_like(prices)\n",
    "        total_capital = np.zeros_like(prices) \n",
    "        quantities = np.zeros_like(prices)\n",
    "        smart_weights_balanced_portfolio = []\n",
    "        for i in range(0, len(weights)):\n",
    "            df = pd.DataFrame()\n",
    "            if i == 0:\n",
    "               quantities[0] = self.invested_capital * weights[i] / prices[i] \n",
    "               total_capital[0] = self.invested_capital * weights[i]\n",
    "            else:\n",
    "                for j in range(1, len(prices[i])):\n",
    "                    if prices[i][j] > prices [i-1][j]:\n",
    "                        funds[i][j] = prices[i][j]  * quantities[i-1][j]\n",
    "                        sold_all[i][j] = 1\n",
    "                    else:       \n",
    "                        sold_all[i][j] = 0\n",
    "                                \n",
    "                quantities[i] =  np.sum(funds[i]) * weights[i] / prices[i]             \n",
    "                  \n",
    "                for k in range(len(quantities[i])):\n",
    "                    if sold_all[i][k] == 0:\n",
    "                        quantities[i][k] += quantities[i-1][k]\n",
    "                        total_capital[i][k]  = quantities[i-1][k] * prices[i-1][k] + quantities[i][k] * prices[i][k]\n",
    "                    else:\n",
    "                        total_capital[i][k] = quantities[i][k] * prices[i][k]\n",
    "                \n",
    "                weights[i] = (total_capital[i] /np.sum(total_capital[i]))\n",
    "                \n",
    "                df[f'prices_t{i-1}'] = prices[i - 1]\n",
    "                df[f'prices_t{i}'] = prices[i]\n",
    "                df[f'weights_t{i-1}'] = weights[i-1]\n",
    "                df[f'weights_t{i}'] = weights[i]\n",
    "                df[f'funds_t{i}'] = funds[i]\n",
    "                df[f'quantities_t{i-1}'] = quantities[i-1]\n",
    "                df[f'quantities_bought_t{i}'] = quantities[i]\n",
    "                df[f'quantities_t{i}'] = quantities[i]\n",
    "                df[f'invested_capital_t{i-1}'] = quantities[i-1] * prices[i-1]\n",
    "                df[f'invested_capital_t{i}'] = total_capital[i]\n",
    "                df[f'cumulative_capital_t{i-1}'] = df[f'invested_capital_t{i-1}'].cumsum()\n",
    "                df[f'cumulative_capital_t{i}'] = df[f'invested_capital_t{i}'].cumsum()\n",
    "                df.index = self.names\n",
    "                smart_weights_balanced_portfolio.append(df)\n",
    "\n",
    "        return smart_weights_balanced_portfolio\n",
    "\n",
    "\n",
    "    def dummy_balancer(self, method='sharpe_control'):\n",
    "        \"\"\"\n",
    "        Adjusts the weights of a portfolio based on the specified method.\n",
    "        \n",
    "        Parameters:\n",
    "        - self: Reference to the instance of the object containing the portfolio data, including prices (`prices`), Sharpe weights (`sharpe_weights`), minimum risk weights (`min_risk_weights`), and invested capital (`invested_capital`).\n",
    "        - method (str, optional): The balancing method to use. Possible values are:\n",
    "        - 'sharpe': Uses the Sharpe weights.\n",
    "        - 'risk': Uses the minimum risk weights.\n",
    "        - 'even': Distributes the weights equally among the assets.\n",
    "        - 'risk_control': Uses a risk control strategy based on the first minimum risk weight.\n",
    "        - Default is 'sharpe_control': Uses the first Sharpe weight.\n",
    "        \n",
    "        Returns:\n",
    "        - simple_weights_balanced_portfolio (list of pandas.DataFrame): A list of DataFrames, each containing the prices, weights, quantities, and capital invested for each asset in each period.\n",
    "        \"\"\"\n",
    "            \n",
    "        prices = self.prices\n",
    "        if method == 'sharpe':\n",
    "            weights = self.sharpe_weights\n",
    "        elif method == 'risk':\n",
    "            weights = self.min_risk_weights\n",
    "        elif method == 'even':\n",
    "            weights = np.full_like(prices, 1 / prices.shape[1])\n",
    "        elif method == 'risk_control':\n",
    "            weights = np.full_like(prices, self.min_risk_weights[0])\n",
    "        else:\n",
    "            weights = np.full_like(prices, self.sharpe_weights[0])\n",
    "            \n",
    "        total_capital = np.zeros_like(prices) \n",
    "        quantities = np.zeros_like(prices)\n",
    "        simple_weights_balanced_portfolio = []\n",
    "\n",
    "        for i in range(1, len(weights)):\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            quantities[i-1] = self.invested_capital * weights[i-1] / prices[i-1] \n",
    "            total_capital[i] = quantities[i-1] * prices[i]   \n",
    "            quantities[i] = np.sum(total_capital[i]) * weights[i] / prices[i]\n",
    " \n",
    "            df[f'prices_t{i-1}'] = prices[i - 1]\n",
    "            df[f'prices_t{i}'] = prices[i]\n",
    "            df[f'weights_t{i-1}'] = weights[i-1]\n",
    "            df[f'weights_t{i}'] = weights[i]\n",
    "            df[f'funds_t{i}'] = prices[i] * quantities[i]\n",
    "            df[f'quantities_t{i-1}'] = quantities[i-1]\n",
    "            df[f'quantities_bought_t{i}'] = quantities[i] - quantities[i-1]\n",
    "            df[f'quantities_t{i}'] = quantities[i]\n",
    "            df[f'invested_capital_t{i-1}'] = quantities[i-1] * prices[i-1]\n",
    "            df[f'invested_capital_t{i}'] = total_capital[i]\n",
    "            df[f'cumulative_capital_t{i-1}'] = df[f'invested_capital_t{i-1}'].cumsum()\n",
    "            df[f'cumulative_capital_t{i}'] = df[f'invested_capital_t{i}'].cumsum()\n",
    "            df.index = self.names\n",
    "            simple_weights_balanced_portfolio.append(df)\n",
    "            \n",
    "        return simple_weights_balanced_portfolio\n",
    "\n",
    "    def get_portfolio_ROI(self):\n",
    "        optimal_ROI = []\n",
    "        portfolios = [\n",
    "            (\"sharpe_control\", self.max_sharpe_control),\n",
    "            (\"sharpe\", self.max_sharpe),\n",
    "            (\"min_risk_control\", self.min_risk_control),\n",
    "            (\"min_risk\", self.min_risk),\n",
    "            (\"even_weights\", self.even_weights),\n",
    "            (\"smart_sharpe_control\", self.smart_max_sharpe_control),\n",
    "            (\"smart_max_sharpe\", self.smart_max_sharpe),\n",
    "            (\"smart_min_risk_control\", self.smart_min_risk_control),\n",
    "            (\"smart_min_risk\", self.smart_min_risk),\n",
    "            (\"smart_even_weights\", self.smart_even_weights)\n",
    "        ]\n",
    "        num_periods = len(portfolios[0][1])\n",
    "        \n",
    "        for i in range(num_periods):\n",
    "            opt_ROI = {} \n",
    "            for name, portfolio in portfolios:\n",
    "                this_opt = portfolio[i][f'cumulative_capital_t{i+1}'].iloc[-1]\n",
    "                previous_opt = portfolio[i][f'cumulative_capital_t{i}'].iloc[-1] if i > 0 else self.invested_capital\n",
    "                previous_ROI = this_opt / previous_opt\n",
    "                latest_ROI = this_opt / self.invested_capital\n",
    "                opt_ROI[name] = {\n",
    "                    \"previous_ROI_df\": round(previous_ROI, 4),\n",
    "                    \"lastest_ROI_df\": round(latest_ROI, 4)\n",
    "                }\n",
    "            optimal_ROI.append(opt_ROI)\n",
    "\n",
    "        #lastest_ROI_df = pd.DataFrame({k: [v[k]['lastest_ROI_df'] for v in optimal_ROI] for k in optimal_ROI[0].keys()})\n",
    "        #previous_ROI_df = pd.DataFrame({k: [v[k]['previous_ROI_df'] for v in optimal_ROI] for k in optimal_ROI[0].keys()})\n",
    "        \n",
    "       # lastest_ROI_df = lastest_ROI_df[~lastest_ROI_df.index.duplicated(keep='first')]\n",
    "       # previous_ROI_df = previous_ROI_df[~previous_ROI_df.index.duplicated(keep='first')]\n",
    "\n",
    "        return optimal_ROI #lastest_ROI_df, #previous_ROI_df\n",
    "\n",
    "    def plot_ROI_over_time(self, return_type='portfolio_ROI', method='smart'):\n",
    "        # Seleciona o DataFrame com base no return_type\n",
    "        if return_type == 'portfolio_ROI':\n",
    "            df = self.portfolio_ROI\n",
    "        elif return_type == 'optimization_ROI':\n",
    "            df = self.optimization_ROI\n",
    "        else:\n",
    "            raise ValueError(\"Invalid return_type. Use 'portfolio_ROI' or 'optimization_ROI'.\")\n",
    "\n",
    "        # Filtra as colunas com base no método\n",
    "        columns_to_plot = [col for col in df.columns if method in col]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        for column in columns_to_plot:\n",
    "            ax.plot(df.index, df[column], label=column)\n",
    "        \n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('ROI')\n",
    "        ax.set_title('ROI Over Time for Different Strategies')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_xticks(df.index)\n",
    "        ax.set_xticklabels(self.dates, rotation=45)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestPortfolios:\n",
    "    def __init__(self, assets, num_combinations, num_assets, window_size=30, seed=52):\n",
    "        self.assets = assets\n",
    "        self.window_size = window_size\n",
    "        self.num_assets = num_assets\n",
    "        self.num_combinations = num_combinations\n",
    "        self.seed = seed\n",
    "        self.combinations = self.generate_combinations()\n",
    "        self.portfolios = self.analyze_portfolios()\n",
    "        self.smart_strategies, self.dummy_strategies = self.normalize_strategies()\n",
    "\n",
    "    def generate_combinations(self):\n",
    "        random.seed(self.seed)\n",
    "        combinations = []\n",
    "        for _ in range(self.num_combinations):\n",
    "            shuffled_assets = self.assets[:]\n",
    "            random.shuffle(shuffled_assets)\n",
    "            combination = random.sample(shuffled_assets, self.num_assets)\n",
    "            concatenated_df = pd.concat(combination, axis=1, join='inner')\n",
    "            if not concatenated_df.empty:\n",
    "                combinations.append(concatenated_df)\n",
    "        return combinations\n",
    "\n",
    "    def analyze_portfolios(self):\n",
    "        portfolios = {}\n",
    "        for i, df in tqdm(enumerate(self.combinations), total=self.num_combinations):\n",
    "            portfolio_name = f'n_assets_{self.num_assets}_window_size_{self.window_size}_{i}'\n",
    "            try:\n",
    "                portfolios[portfolio_name] = Portfolio(data=df, invested_capital=100000, window_size=self.window_size)\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing portfolio {portfolio_name}: {e}\")\n",
    "        return portfolios\n",
    "\n",
    "    def normalize_strategies(self, return_type='portfolio_ROI', roi_type='lastest_ROI_df', period='last'):\n",
    "        smart_normalized_strategies = []\n",
    "        dummy_normalized_strategies = []\n",
    "        for _, plf in self.portfolios.items():\n",
    "            roi_data = getattr(plf, return_type)\n",
    "\n",
    "            if not roi_data: \n",
    "                continue\n",
    "\n",
    "            if period == 'last':\n",
    "                roi_data = [roi_data[-1]]\n",
    "\n",
    "            for period_data in roi_data:\n",
    "                smart_denominator = period_data.get('smart_even_weights', {}).get(roi_type, 1)\n",
    "                dummy_denominator = period_data.get('even_weights', {}).get(roi_type, 1)\n",
    "\n",
    "                smart_normalized = {key: value.get(roi_type, 0) / smart_denominator\n",
    "                                    for key, value in period_data.items()\n",
    "                                    if 'smart' in key and 'smart_even_weights' not in key\n",
    "                                    }\n",
    "                dummy_normalized = {key: value.get(roi_type, 0) / dummy_denominator\n",
    "                                    for key, value in period_data.items()\n",
    "                                    if 'smart' not in key and 'even_weights' not in key\n",
    "                                    }\n",
    "\n",
    "                smart_normalized_strategies.append(smart_normalized)\n",
    "                dummy_normalized_strategies.append(dummy_normalized)\n",
    "\n",
    "        return smart_normalized_strategies, dummy_normalized_strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestAnalysis:\n",
    "    def __init__(self, smart_strategies=None, dummy_strategies=None, load: bool = False, window_size: list = None):\n",
    "        self.smart_strategies = smart_strategies if smart_strategies else []\n",
    "        self.dummy_strategies = dummy_strategies if dummy_strategies else []\n",
    "        self.load = load\n",
    "        self.window_size = window_size if window_size else [30, 60, 90, 120, 150, 180]\n",
    "\n",
    "        if self.load:\n",
    "            self.load_optimizations()\n",
    "    \n",
    "    def load_optimizations(self):\n",
    "        base_dir = '..\\\\pkl'\n",
    "        all_smart_strategies = {ws: [] for ws in self.window_size}\n",
    "        all_dummy_strategies = {ws: [] for ws in self.window_size}\n",
    "        \n",
    "        for filename in os.listdir(base_dir):\n",
    "            if filename.endswith('.pkl'):\n",
    "                for ws in self.window_size:\n",
    "                    if f'window_{str(ws)}' in filename:\n",
    "                        file_path = os.path.join(base_dir, filename)\n",
    "                        try:\n",
    "                            with open(file_path, 'rb') as file:\n",
    "                                backtest_portfolio = pickle.load(file)\n",
    "                                all_smart_strategies[ws].extend(backtest_portfolio.smart_strategies)\n",
    "                                all_dummy_strategies[ws].extend(backtest_portfolio.dummy_strategies)\n",
    "                        except (pickle.UnpicklingError, EOFError, KeyError) as e:\n",
    "                            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "        self.smart_strategies = all_smart_strategies\n",
    "        self.dummy_strategies = all_dummy_strategies\n",
    "    \n",
    "    def test_distribution(self, strategy_type='smart', keys='all'):\n",
    "        \"\"\"\n",
    "        Tests the distribution of data from a specified type of strategy (smart or dummy) for normality.\n",
    "\n",
    "        Parameters:\n",
    "        strategy_type (str): The type of strategy to test. Either 'smart' or 'dummy'.\n",
    "        keys (str or list, optional): \n",
    "        The keys to test. If 'all', tests all keys found in the strategies. \n",
    "        If a list of keys, only tests the specified keys. Default is 'all'.\n",
    "\n",
    "        Returns:\n",
    "        list of dict: A list of dictionaries containing the results of the normality test for each key.\n",
    "            Each dictionary has the following keys:\n",
    "            - 'key': The key being tested.\n",
    "            - 'normal': A boolean indicating if the distribution is normal (p-value > 0.05).\n",
    "            - 'p_value': The p-value from the Shapiro-Wilk test for normality.\n",
    "        \"\"\"\n",
    "        distribution_results = []\n",
    "        \n",
    "        if strategy_type == 'smart':\n",
    "            strategies = []\n",
    "            for ws in self.window_size:\n",
    "                strategies.extend(self.smart_strategies.get(ws, []))\n",
    "        elif strategy_type == 'dummy':\n",
    "            strategies = []\n",
    "            for ws in self.window_size:\n",
    "                strategies.extend(self.dummy_strategies.get(ws, []))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy_type. Must be 'smart' or 'dummy'.\")\n",
    "\n",
    "\n",
    "        if keys == 'all':\n",
    "            all_keys = set().union(*(strategy.keys() for strategy in strategies))\n",
    "        else:\n",
    "            all_keys = keys\n",
    "                \n",
    "        all_data = {key: [] for key in all_keys}\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            for key in all_data.keys():\n",
    "                value = strategy.get(key, None)\n",
    "                if value is not None:\n",
    "                    if isinstance(value, (list, np.ndarray)):\n",
    "                        all_data[key].extend(value)\n",
    "                    else:\n",
    "                        all_data[key].append(value)\n",
    "                        \n",
    "        for key in all_data.keys():\n",
    "            if len(all_data[key]) >= 3:\n",
    "                _, p_value = shapiro(all_data[key])\n",
    "                normal = p_value > 0.05\n",
    "\n",
    "                distribution_results.append({\n",
    "                    'key': key,\n",
    "                    'normal': normal,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "                \n",
    "\n",
    "                if normal:\n",
    "                    self.plot_histogram(all_data[key], f'{strategy_type}_{key}')\n",
    "                else:\n",
    "                    self.plot_kde(all_data[key], f'{strategy_type}_{key}')\n",
    "            else:\n",
    "                print(f\"Insufficient data for key '{key}' to perform normality test.\")\n",
    "        \n",
    "        return distribution_results\n",
    "\n",
    "    \n",
    "    def plot_histogram(self, data, strategy, prob=1, auto_save=True):\n",
    "        \"\"\"\n",
    "        Plots a histogram of initial returns for a specific strategy and adjusts the bar colors based on data quartiles.\n",
    "\n",
    "        Args:\n",
    "            data (list or array-like): List or array containing the initial return data to be plotted.\n",
    "            strategy (str): The name of the strategy to be included in the chart title and legend.\n",
    "            prob (float, optional): Probability value to highlight with a vertical line on the chart. Default is 1.\n",
    "            auto_save (bool, optional): If True, automatically saves the generated chart as a PNG file. Default is True.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Note:\n",
    "            - The generated chart includes:\n",
    "            - A histogram of the data with bars colored according to quartiles.\n",
    "            - A black line representing the normal distribution fitted to the data.\n",
    "            - A red vertical line indicating the value specified by `prob`.\n",
    "            - The probability of returns greater than `prob` displayed in the legend.\n",
    "\n",
    "        Example:\n",
    "            >>> plot_histogram(data=[0.1, 0.5, 0.3, 0.7], strategy='StrategyA', prob=0.2)\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))  # Create a figure and axis object\n",
    "\n",
    "        q1, q2, q3 = np.percentile(data, [25, 50, 75])\n",
    "        n, bins, patches = ax.hist(data, bins=30, alpha=0.7, label=strategy, edgecolor='black')\n",
    "\n",
    "        for patch, bin_left in zip(patches, bins[:-1]):\n",
    "            if bin_left < q1:\n",
    "                patch.set_facecolor('red')\n",
    "            elif bin_left < q2:\n",
    "                transition_ratio = (bin_left - q1) / (q2 - q1)\n",
    "                patch.set_facecolor(plt.cm.Blues(transition_ratio))\n",
    "            elif bin_left < q3:\n",
    "                transition_ratio = (bin_left - q2) / (q3 - q2)\n",
    "                patch.set_facecolor(plt.cm.Blues(transition_ratio))\n",
    "            else:\n",
    "                patch.set_facecolor('blue')\n",
    "\n",
    "            mu, std = norm.fit(data)\n",
    "            bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "            p = norm.pdf(bin_centers, mu, std)\n",
    "            p_scaled = p * np.max(n) / np.max(p)\n",
    "            ax.plot(bin_centers, p_scaled, 'k', linewidth=2, label='Normal Distribution', alpha=0.5)\n",
    "            ax.axvline(x=1, color='r', linestyle='--', label='Value 1')\n",
    "            probability = np.sum(np.array(data) > prob) / len(data)\n",
    "            ax.legend([f'Probability of returns > 1: {probability:.2f}'])\n",
    "            ax.set_title(f'Histogram of Initial Returns for: {strategy}  for {len(data)} combinations')\n",
    "            ax.set_xlabel('Last_ROI')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_xlim(min(data) - 0.1 * abs(min(data)), max(data) + 0.1 * abs(max(data)))\n",
    "            ax.set_ylim(0, max(n) + 0.25 * max(n))\n",
    "            ax.grid(True)\n",
    "\n",
    "            if auto_save:\n",
    "                fig_name = f'backtest_for_{len(data)}_combinations_{self.window_size}_for_strategy_{strategy}.png'\n",
    "                fig.savefig(fig_name, bbox_inches='tight')  # Save the figure with tight bounding box\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    def plot_kde(self, data, strategy, prob=1, auto_save=True):\n",
    "        \"\"\"\n",
    "        Plots a Kernel Density Estimate (KDE) plot of initial returns for a specific strategy and highlights different data quartiles.\n",
    "\n",
    "        Args:\n",
    "            data (list or array-like): List or array containing the initial return data to be plotted.\n",
    "            strategy (str): The name of the strategy to be included in the chart title and legend.\n",
    "            prob (float, optional): Probability value to highlight with a vertical line on the chart. Default is 1.\n",
    "            auto_save (bool, optional): If True, automatically saves the generated chart as a PNG file. Default is True.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Note:\n",
    "            - The generated chart includes:\n",
    "            - A KDE plot with different shades of blue for different data quartiles.\n",
    "            - A red vertical line indicating the value specified by `prob` and displaying the probability of data greater than `prob`.\n",
    "            - The KDE plot is displayed with appropriate x and y limits, and the chart is saved if `auto_save` is True.\n",
    "\n",
    "        Example:\n",
    "            >>> plot_kde(data=[0.1, 0.5, 0.3, 0.7], strategy='StrategyA', prob=0.2)\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))  # Create a figure and axis object\n",
    "\n",
    "        kde = gaussian_kde(data)\n",
    "        x_values = np.linspace(min(data) - 0.1 * abs(min(data)), max(data) + 0.1 * abs(max(data)), 1000)\n",
    "        y_values = kde(x_values)\n",
    "        q1, q2, q3 = np.percentile(data, [25, 50, 75])\n",
    "        ax.fill_between(x_values, y_values, where=(x_values < q1), color=plt.cm.Blues(0.2), alpha=0.5)\n",
    "        ax.fill_between(x_values, y_values, where=(x_values >= q1) & (x_values < q2), color=plt.cm.Blues(0.4), alpha=0.5)\n",
    "        ax.fill_between(x_values, y_values, where=(x_values >= q2) & (x_values < q3), color=plt.cm.Blues(0.6), alpha=0.5)\n",
    "        ax.fill_between(x_values, y_values, where=(x_values >= q3), color=plt.cm.Blues(0.8), alpha=0.5)\n",
    "        prob_greater_than = np.sum(np.array(data) > prob) / len(data)\n",
    "        ax.axvline(x=1, color='r', linestyle='--', label=f'Probability > {prob}: {prob_greater_than:.2f} for {len(data)} combinations')\n",
    "        ax.set_title(f'KDE Plot - {strategy}')\n",
    "        ax.set_xlabel('ROI_initial_period')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(min(data) - 0.1 * abs(min(data)), max(data) + 0.1 * abs(max(data)))\n",
    "        ax.set_ylim(0, np.max(y_values) + 0.25 * np.max(y_values))\n",
    "        ax.grid(False)\n",
    "\n",
    "        if auto_save:\n",
    "            fig_name = f'backtest_for_{len(data)}_combinations_window_size_{self.window_size[0]}_for_strategy_{strategy}.png'\n",
    "            fig.savefig(fig_name, bbox_inches='tight')  # Save the figure with tight bounding box\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def get_results(self, strategy='smart', prob=1, auto_save=True):\n",
    "        \"\"\"\n",
    "        Calculates and returns the probability of each metric for the given strategy.\n",
    "\n",
    "        Args:\n",
    "            strategy (str, optional): Strategy type, either 'smart' or 'dummy'. Default is 'smart'.\n",
    "            prob (float, optional): Threshold probability value. Default is 1.\n",
    "            auto_save (bool, optional): If True, automatically saves the resulting DataFrame as a CSV file. Default is True.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the probabilities of each metric for the specified strategy.\n",
    "        \"\"\"\n",
    "        if strategy == 'smart':\n",
    "            all_strategies = self.smart_strategies\n",
    "        else:\n",
    "            all_strategies = self.dummy_strategies\n",
    "\n",
    "        probabilities_dict = {}\n",
    "\n",
    "        for key, strategies in all_strategies.items():\n",
    "            metrics = {}\n",
    "            metric_count = {}\n",
    "\n",
    "            for strategy in strategies:\n",
    "                for metric, value in strategy.items():\n",
    "                    if metric not in metrics:\n",
    "                        metrics[metric] = 0\n",
    "                        metric_count[metric] = 0\n",
    "\n",
    "                    if value > prob:\n",
    "                        metrics[metric] += 1\n",
    "                    metric_count[metric] += 1\n",
    "            \n",
    "            probabilities = {metric: (metrics[metric] / metric_count[metric] if metric_count[metric] > 0 else 0)\n",
    "                            for metric in metric_count}\n",
    "            \n",
    "            probabilities_dict[key] = probabilities\n",
    "\n",
    "        df_probabilities = pd.DataFrame(probabilities_dict).T\n",
    "        df_probabilities = df_probabilities.round(3)\n",
    "\n",
    "        if auto_save:\n",
    "            csv_file_name = f'probabilities_for_{strategy}_strategies.csv'\n",
    "            df_probabilities.to_csv(csv_file_name, index=True)\n",
    "\n",
    "        return df_probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file backtest_5_assets_for_200_window_120_seed_37.pkl: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "analysis = BacktestAnalysis(load=True, window_size=[30, 60,90, 120, 150, 180])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.test_distribution(strategy_type='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_probabilities(strategy='smart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_probabilities(strategy='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
