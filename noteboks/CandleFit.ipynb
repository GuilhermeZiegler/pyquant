{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CandleFit:\n",
    "    def __init__(self, market_data: pd.DataFrame = None, ticker: str = None, timeframe: str = '5y'):\n",
    "        \"\"\"\n",
    "        Initializes the CandleFit object with a specified ticker and timeframe.\n",
    "\n",
    "        Parameters:\n",
    "        ticker (str): The ticker symbol of the stock.\n",
    "        market_data (pd.DataFrame): A dataframe containing HLOC and volume in columns. Must indexed in days and timeframe\n",
    "        timeframe (str): The timeframe for which to download dataorical data and to load market_data\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.timeframe = timeframe\n",
    "        self.market_data = market_data\n",
    "        self.data = self.get_data()\n",
    "        # self.features = self.get_price_features()\n",
    "        # self.threshold_dict: dict = None\n",
    "      \n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Downloads dataorical data for the specified ticker and timeframe or loads a previous file containing HLOC and volume.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the dataorical data with a combined datetime index.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.ticker is not None:\n",
    "            try:\n",
    "                ticker_obj = yf.Ticker(self.ticker)\n",
    "                data = ticker_obj.dataory(interval=self.timeframe.lower())\n",
    "                data.index = pd.to_datetime(data.index).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                data.columns = [col.lower() for col in data.columns]\n",
    "                return data\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading ticker: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        else:\n",
    "            valid_timeframes = ['M1', 'M5', 'M15', 'M30', 'H1', 'H4', 'D1', 'W1', 'MN']\n",
    "            if self.timeframe not in valid_timeframes:\n",
    "                print(f\"Invalid timeframe. Please select one of the following: {valid_timeframes}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            if self.market_data is not None:\n",
    "                file_path = os.path.abspath(self.market_data)\n",
    "                display(file_path)\n",
    "                file_ext = os.path.splitext(file_path)[-1].lower()\n",
    "                display(file_ext)\n",
    "                try:\n",
    "                    if file_ext == \".csv\":\n",
    "                        df = pd.read_csv(file_path, parse_dates=[['Date', 'Time']])\n",
    "                    elif file_ext == \".xlsm\":\n",
    "                        df = pd.read_excel(file_path, engine='openpyxl', parse_dates=[['Date', 'Time']])\n",
    "                    elif file_ext == \".parquet\":\n",
    "                        df = pd.read_parquet(file_path)\n",
    "                        df['Datetime'] = pd.to_datetime(df['Date_Time'])\n",
    "                        df.drop(columns=['Date_Time'], inplace=True)\n",
    "                    else:\n",
    "                        display(\"Unsupported file type\")\n",
    "                        return pd.DataFrame()\n",
    "                except Exception as e:\n",
    "                    display(f\"Error loading market data: {e}\")\n",
    "                    return pd.DataFrame()\n",
    "            else:\n",
    "                display(\"No market data or ticker specified.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            timeframe_mapping = {\n",
    "                'M1': '1min', 'M5': '5min', 'M15': '15min', 'M30': '30min',\n",
    "                'H1': '1H', 'H4': '4H', 'D1': '1D', 'W1': '1W', 'MN': '1M'\n",
    "            }\n",
    "            resample_freq = timeframe_mapping.get(self.timeframe.upper())\n",
    "            df.set_index('Datetime', inplace=True)\n",
    "            data = df.resample(resample_freq).agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last',\n",
    "                'volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_dict(key: str) -> dict:\n",
    "        \"\"\"\n",
    "        Loads a dictionary from a pickle file based on the provided key.\n",
    "\n",
    "        Parameters:\n",
    "        key (str): The key to search for in the dictionary.\n",
    "\n",
    "        Returns:\n",
    "        dict: The dictionary associated with the provided key.\n",
    "\n",
    "        Raises:\n",
    "        FileNotFoundError: If the pickle file is not found.\n",
    "        KeyError: If the key is not found in the dictionary.\n",
    "        ValueError: If there is an error loading the pickle file.\n",
    "        \"\"\"\n",
    "        filepath = os.path.join('..', 'pkl', 'threshold_dicts.pkl')\n",
    "        try:\n",
    "            with open(filepath, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "            \n",
    "            for item in data:\n",
    "                if key in item:\n",
    "                    return item[key]\n",
    "            raise KeyError(f\"Key '{key}' not found in the threshold dictionary.\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"The file '{filepath}' was not found.\")\n",
    "        except pickle.PickleError:\n",
    "            raise ValueError(\"Error occurred while loading the pickle file.\")\n",
    "        \n",
    "    def get_price_features(self):\n",
    "        \"\"\"\n",
    "        Calculates various price and volume features from dataorical data.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the calculated features.\n",
    "        \"\"\"\n",
    "        aux = self.data.copy()\n",
    "        df = pd.DataFrame(index=aux.index)\n",
    "        df.index = pd.to_datetime(df.index).strftime('%Y-%m-%d')\n",
    "        df['return_rate'] = aux['close'].pct_change()\n",
    "        df['volume_change'] = aux['volume'].diff()\n",
    "        df['volume_var'] = aux['volume'].pct_change() + 1\n",
    "        df['price_range'] = aux['high'] - aux['low']\n",
    "        df['price_var'] = df['price_range'] / aux['low']\n",
    "        df['price_change'] = aux['close'] - aux['open']\n",
    "        df['close_vol'] = aux['close'].expanding().std()\n",
    "        df['low_vol'] = aux['low'].expanding().std()\n",
    "        df['high_vol'] = aux['high'].expanding().std()\n",
    "        df['open_vol'] = aux['open'].expanding().std()\n",
    "        df['upper_wick'] = aux['high'] - aux[['open', 'close']].max(axis=1)\n",
    "        df['lower_wick'] = aux[['open', 'close']].min(axis=1) - aux['low']\n",
    "        df['wick_change'] = df['upper_wick'] - df['lower_wick']\n",
    "        df['wick_var'] = df['wick_change'] / df['lower_wick']\n",
    "        df['std_wick'] = df['wick_change'].abs().expanding().std()\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        df = pd.concat([aux, df], axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def get_candle_features(self, \n",
    "                            doji_threshold: float =  0.002, \n",
    "                            bullish_threshold : float =  0.005,\n",
    "                            bearish_threshold: float =  0.005,\n",
    "                            volatility_window: int = 7):\n",
    "                            \n",
    " \n",
    "        \"\"\"\n",
    "        Calculates various candlestick features based on price data and a threshold dictionary.\n",
    "\n",
    "        Parameters:\n",
    "        threshold_dict (dict): A dictionary containing thresholds for calculating features. If None, it loads the default dictionary.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the calculated candlestick features.\n",
    "        \"\"\"\n",
    "        \n",
    "        aux = self.features.copy()\n",
    "        aux = aux.loc[:, ~aux.columns.duplicated()]\n",
    "        df = pd.DataFrame(index=aux.index)\n",
    "        df[f'std_volatility_window'] = aux['price_change'].rolling(window=volatility_window).std().abs()\n",
    "        df['bearish_threshold'] = pd.to_numeric(bearish_threshold * df[f'std_volatility_window'], errors='coerce').fillna(0)\n",
    "        df['bullish_threshold'] = pd.to_numeric(bullish_threshold * df[f'std_volatility_window'], errors='coerce').fillna(0)\n",
    "        df['is_bearish'] = (aux['close'] <= (aux['open'] - df['bearish_threshold'])).astype(int)\n",
    "        df['is_bullish'] = (aux['close'] >= (aux['open'] + df['bullish_threshold'])).astype(int)\n",
    "        df['is_doji'] = (abs(aux['close'] - aux['open']) <= doji_threshold).astype(int)\n",
    "        df['is_bearish_open_gap'] = (aux['open'] < aux['close'].shift(1)).astype(int)\n",
    "        df['is_bullish_open_gap'] = (aux['open'] > aux['close'].shift(1)).astype(int)\n",
    "    \n",
    "        df = pd.concat([aux, df], axis=1)\n",
    "        self.features = df\n",
    "        return  self.features\n",
    "\n",
    "    def fit_morning_star(self,\n",
    "                         doji_threshold: float = 0.002,\n",
    "                         bullish_to_bearish_ratio : float = 0.33,\n",
    "                         bearish_threshold: float = 0.2):\n",
    "                  \n",
    "        \"\"\"\n",
    "        Identifies the morning star candlestick pattern in the dataorical data.\n",
    "\n",
    "        Parameters:\n",
    "        doji_threshold (float): The threshold for the price change to identify a doji candle. Default is 0.002.\n",
    "        bullish_threshold (float): The ratio of the price change on the third day to the price change on the first day to identify a bullish candle. Default is 0.33.\n",
    "        bearish_threshold (float): The threshold to identify a bearish candle on the first day. Default is 0.2.\n",
    "        volatility_window (int): The window size (in days) for calculating the volatility of the dataorical data. Default is 7.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame with a column indicating the presence of the morning star pattern.\n",
    "        \"\"\"\n",
    "        df = self.get_candle_features()\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='last')]\n",
    "\n",
    "        # Condition 1: Two days ago was a bearish candle and the close of that day is lower than the open of that day adjusted by the threshold\n",
    "        df['is_bearish_morning_star'] = ((df['is_bearish'].shift(2) == 1) & \n",
    "                                        (df['close'].shift(2) + bearish_threshold * df['price_change'].shift(2) \n",
    "                                        <= df['open'].shift(2))).astype(int)\n",
    "\n",
    "        # Condition 2: The previous day was a doji candle and had a bearish open gap\n",
    "        df['is_bearish_open_gap_morning_star'] = (df['is_bearish_open_gap'].shift(1) == 1).astype(int)\n",
    "        df['is_doji_morning_star'] = (df['price_change'].shift(1).abs() <= doji_threshold ).astype(int)\n",
    "\n",
    "        # Condition 3: Today is a bullish candle and the price change from two days ago to today is significant\n",
    "        df['is_bullish_morning_star'] = ((df['is_bullish'] == 1) & \\\n",
    "                                        (df['close'] - df['close'].shift(2) >= bullish_to_bearish_ratio)\n",
    "                                        * df['price_change'].shift(2).abs()).astype(int)\n",
    "\n",
    "        # Combine all conditions to determine the morning star pattern\n",
    "        df['is_morning_star'] = df[['is_bearish_morning_star', 'is_bearish_open_gap_morning_star', 'is_doji_morning_star', \n",
    "                                    'is_bullish_morning_star']].all(axis=1).astype(int)\n",
    "\n",
    "        self.features = df\n",
    "        return self.features\n",
    "    \n",
    "    \n",
    "    def fit_hammer(self,\n",
    "                   lower_wick_to_price_change_ratio: float = 3,\n",
    "                   upper_wick_to_price_change_ratio: float = 0.02,\n",
    "                   volatility_window: int = None):\n",
    "        \"\"\"\n",
    "        Identifies the hammer candlestick pattern in the dataorical data.\n",
    "\n",
    "        Parameters:\n",
    "        lower_wick_to_price_change_ratio (float): The minimum ratio of the lower wick length to the price change to identify a hammer handle. Default is 4.\n",
    "        upper_wick_to_price_change_ratio (float): The maximum ratio of the upper wick length to the price change to identify a hammer head. Default is 0.05.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame with columns indicating the presence of the hammer pattern and its components.\n",
    "        \"\"\"\n",
    "        df = self.get_candle_features(volatility_window).copy()\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='last')]\n",
    "\n",
    "        # Condition 1: Two days ago was a bearish candle and the close of that day is lower than the open of that day adjusted by the threshold\n",
    "        df['is_hammer_head'] =  (df['upper_wick'] <= upper_wick_to_price_change_ratio * df['std_volatility_window']).astype(int)\n",
    "        df['is_hammer_handle'] =  (df['lower_wick'] / df['price_change'].abs() >= df['std_volatility_window'] * lower_wick_to_price_change_ratio).astype(int)\n",
    "        df['is_hammer'] = df[['is_hammer_head', 'is_hammer_handle']].all(axis=1).astype(int)\n",
    "\n",
    "        self.features = df\n",
    "        return self.features\n",
    "\n",
    "    \n",
    "    def get_movings(self, short:int = None, long:int = None, strategy: str = 'test'):\n",
    "\n",
    "        \"\"\"\n",
    "        Calculates buy and sell signals based on moving averages for different strategies and parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - threshold_dict (dict, optional): Dictionary containing moving average settings for different strategies. If any of parameters is None,\n",
    "        it will be loaded with `self.load_dict(key='rolling_cross_dict')` and available strategies will be measured.  \n",
    "        - short (int, optional): Time window for the short moving average. Not used directly in the function.\n",
    "        - long_ (int, optional): Time window for the long moving average. Not used directly in the function.\n",
    "        - signal_window (int, optional): Time window for signal calculation. Not used directly in the function.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame with additional columns for moving averages and buy/sell signals.\n",
    "        \"\"\"\n",
    "        df = self.get_candle_features()  \n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='last')]\n",
    "        \n",
    "        if (short is None) != (long is None):\n",
    "            raise ValueError(\"Please set both short and long to valid int or set both to None.\")\n",
    "        elif all(x is not None for x in (short, long)):\n",
    "            threshold_dict = {f'{strategy}_{short}_{long}': {'short': short, 'long': long}}\n",
    "        else:\n",
    "            display('Loading standard strategies')\n",
    "            threshold_dict = self.load_dict(key='rolling_cross_dict')\n",
    "\n",
    "        tolerance = 0.015 * df['close_vol']  \n",
    "        for key, value in threshold_dict.items():\n",
    "            strategy = key.split('_')[0] if '_' in key else key\n",
    "            short = value['short']\n",
    "            long = value['long']\n",
    "            \n",
    "            df.loc[:, f'{strategy}_short_{short}'] = df['close'].rolling(window=short, min_timeframes=1).mean()\n",
    "            df.loc[:, f'{strategy}_long_{long}'] = df['close'].rolling(window=long, min_timeframes=1).mean()\n",
    "            \n",
    "            \n",
    "            buy = (df[f'{strategy}_short_{short}'] > df[f'{strategy}_long_{long}'] + tolerance) & \\\n",
    "                (df[f'{strategy}_short_{short}'].shift(1) < df[f'{strategy}_long_{long}'].shift(1) + tolerance)\n",
    "            \n",
    "            sell = (df[f'{strategy}_short_{short}'] < df[f'{strategy}_long_{long}'] - tolerance) & \\\n",
    "                (df[f'{strategy}_short_{short}'].shift(1) > df[f'{strategy}_long_{long}'].shift(1) - tolerance)\n",
    "            \n",
    "            df.loc[:, f'{strategy}_{short}_{long}'] = np.where(buy, 1, np.where(sell, -1, 0))\n",
    "\n",
    "                        \n",
    "        self.features = df\n",
    "        self.threshold_dict = threshold_dict  \n",
    "        return self.features          \n",
    "\n",
    "    def candlestick_chart(self, \n",
    "                      key: str = 'is_morning_star', \n",
    "                      plot_type: str = 'pattern',\n",
    "                      height: int = 1200, \n",
    "                      offset: float = 12):\n",
    "        \"\"\"\n",
    "        Generates a candlestick chart with optional pattern or price action markers.\n",
    "\n",
    "        Parameters:\n",
    "        - key (str): Key for identifying the pattern or price action indicators. Defaults to 'is_morning_star'.\n",
    "        - plot_type (str): Type of plot to generate. Options are 'pattern' or 'price_action'. Defaults to 'pattern'.\n",
    "        - height (int): Height of the plot in pixels. Defaults to 900.\n",
    "        - offset (float): Vertical offset for pattern markers. Defaults to 12.\n",
    "\n",
    "        Returns:\n",
    "        - go.Figure: A Plotly Figure object with the candlestick chart.\n",
    "        \"\"\"\n",
    "        \n",
    "        aux = self.features.copy()\n",
    "        aux = aux.loc[:, ~aux.columns.duplicated(keep='last')]\n",
    "        \n",
    "        if key not in aux.columns:\n",
    "            print(f\"Key '{key}' not found in aux columns.\")\n",
    "            return None\n",
    "\n",
    "        trace = go.Candlestick(\n",
    "            x=aux.index,\n",
    "            open=aux[\"open\"],\n",
    "            high=aux[\"high\"],\n",
    "            low=aux[\"low\"],\n",
    "            close=aux[\"close\"],\n",
    "            name=self.ticker,\n",
    "            yaxis=\"y\"\n",
    "        )\n",
    "        \n",
    "        volume_colors = ['green' if aux['volume'][i] > aux['volume'][i-1] else 'red' for i in range(1, len(aux))]\n",
    "        volume_colors.insert(0, 'green')\n",
    "        volume_trace = go.Bar(\n",
    "                x=aux.index,\n",
    "                y=aux['volume'],\n",
    "                marker_color=volume_colors,\n",
    "                name='Volume',\n",
    "                yaxis=\"y2\"\n",
    "            )\n",
    "            \n",
    "        \n",
    "        if plot_type == 'pattern':     \n",
    "            markers = aux[aux[key] == 1].copy()\n",
    "            markers['close'] = markers['low'] - offset\n",
    "            markers = markers.dropna(subset=['close'])\n",
    "            marker_trace = go.Scatter(\n",
    "                x=markers.index,\n",
    "                y=markers['close'],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color='blue',\n",
    "                    size=8,\n",
    "                    symbol='triangle-up'\n",
    "                ),\n",
    "                name=key,\n",
    "                yaxis=\"y\")\n",
    "            \n",
    "            data = [trace, marker_trace, volume_trace]\n",
    "            \n",
    "        elif plot_type == 'moving_cross':\n",
    "            strategy, short, long = key.split('_')\n",
    "            short_col = f'{strategy}_short_{short}'\n",
    "            long_col = f'{strategy}_long_{long}'\n",
    "            signal_col = f'{strategy}_{short}_{long}'\n",
    "            short_trace = go.Scatter(\n",
    "                x=aux.index,\n",
    "                y=aux[short_col],\n",
    "                mode='lines',\n",
    "                name=f'{strategy.capitalize()} Short {short}',\n",
    "                line=dict(color='purple')  \n",
    "            )\n",
    "            long_trace = go.Scatter(\n",
    "                x=aux.index,\n",
    "                y=aux[long_col],\n",
    "                mode='lines',\n",
    "                name=f'{strategy.capitalize()} Long {long}',\n",
    "                line=dict(color='orange')  \n",
    "            )\n",
    "\n",
    "            markers = aux[aux[signal_col] != 0].copy()  \n",
    "            markers['close'] = markers.apply(\n",
    "                lambda row: row['low'] - offset if row[signal_col] == 1 else row['high'] + offset,\n",
    "                axis=1\n",
    "            )\n",
    "            markers['color'] = markers[signal_col].apply(lambda x: 'green' if x == 1 else 'red')\n",
    "            markers['symbol'] = markers[signal_col].apply(lambda x: 'arrow-up' if x == 1 else 'arrow-down')\n",
    "            \n",
    "            marker_trace = go.Scatter(\n",
    "                x=markers.index,\n",
    "                y=markers['close'],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=markers['color'],\n",
    "                    size=8,\n",
    "                    symbol=markers['symbol']\n",
    "                ),\n",
    "                name='Signal',\n",
    "                yaxis=\"y\"\n",
    "            )\n",
    "            \n",
    "           \n",
    "            data = [trace, short_trace, long_trace, marker_trace, volume_trace]\n",
    "        \n",
    "        layout = go.Layout(\n",
    "            title=f\"{self.ticker} Candlestick Chart markers: {key.capitalize()}\",\n",
    "            xaxis=dict(title=\"Date\"),\n",
    "            yaxis=dict(title=\"Price\", domain=[0.3, 1]),\n",
    "            yaxis2=dict(title=\"Volume\", domain=[0, 0.2]),\n",
    "            height=height,\n",
    "            barmode='relative'\n",
    "        )\n",
    "        \n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        return fig\n",
    "        \n",
    "    def get_trades(self,  \n",
    "                   strategy: str = None,\n",
    "                   reward_risk_ratio: list = None, \n",
    "                   price_col: str = 'close',\n",
    "                   trade_timeframe=7,\n",
    "                   target_return=0.01):\n",
    "        \"\"\"\n",
    "        Calculates potential trades based on a given strategy and parameters.\n",
    "\n",
    "        Parameters:\n",
    "        df (DataFrame): The DataFrame containing price data and strategy signals.\n",
    "        strategy (str): The column name of the strategy signals (1 for buy, -1 for sell).\n",
    "        reward_risk_ratio (list): List of reward to risk ratios to consider.\n",
    "        price_col (str): The column name to use as the price for entering trades.\n",
    "        trade_timeframe (int): The number of timeframes to look ahead for the trade.\n",
    "        target_return (float): The target return for each trade.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The DataFrame with trade information, results, and positions.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.features.copy()\n",
    "        \n",
    "        cols = ['open', 'high', 'low', 'close']\n",
    "        shifted_cols = []\n",
    "        stop_loss_cols = []\n",
    "        \n",
    "        for col in cols:\n",
    "            for i in range(2, trade_timeframe + 1):\n",
    "                df[f'{col}_{i}'] = df[col].shift(-i)\n",
    "                shifted_cols.append(f'{col}_{i}')\n",
    "        \n",
    "        has_signals = (df[strategy] == 1) | (df[strategy] == -1)\n",
    "        if not has_signals.any():\n",
    "            return \"The strategy did not generate buy or sell signals.\"\n",
    "        \n",
    "        df = df[cols + [strategy] + shifted_cols][has_signals].copy()\n",
    "        df['side'] = df[strategy].apply(lambda x: 'long' if x == 1 else 'short')\n",
    "        df['tp'] = df.apply(lambda row: (1 + target_return) * row[price_col] if row[strategy] == 1 else (1 - target_return) * row[price_col], axis=1)\n",
    "        if reward_risk_ratio is None:      \n",
    "            reward_risk_ratio = np.arange(0.5, 2.50, 0.5)\n",
    "        \n",
    "        for rr in reward_risk_ratio:\n",
    "            df[f'sl_{rr}'] = np.where(df['side'] == 'long', df[price_col] * (1 - target_return * rr),df[price_col] * (1 + target_return * rr))\n",
    "            stop_loss_cols.append(f'sl_{rr}')\n",
    "\n",
    "    \n",
    "        for loss_col in stop_loss_cols:\n",
    "            df[f'out_day_{loss_col}'] = np.nan\n",
    "            df[f'result_{loss_col}'] = np.nan\n",
    "            df[f'result_{loss_col}_value'] = np.nan\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                stop_loss_val = row[loss_col]\n",
    "                target_price = row['tp']\n",
    "                entry_price = row[price_col] \n",
    "                \n",
    "                for i in range(2, trade_timeframe + 1):\n",
    "                    next_open = row[f'open_{i}']\n",
    "                    next_high = row[f'high_{i}']\n",
    "                    next_low = row[f'low_{i}']\n",
    "                    next_close = row[f'close_{i}']\n",
    "                    \n",
    "                    if row['side'] == 'long':\n",
    "                        price_vars = [next_open, next_low, next_high, next_close]\n",
    "                        for price_var in price_vars:\n",
    "                            if price_var > target_price:\n",
    "                                df.at[index, f'out_day_{loss_col}'] = int(i)\n",
    "                                df.at[index, f'result_{loss_col}'] = 'profit'\n",
    "                                df.at[index, f'result_{loss_col}_value'] = price_var - entry_price\n",
    "                                break\n",
    "                            elif price_var < stop_loss_val:\n",
    "                                df.at[index, f'out_day_{loss_col}'] = int(i)\n",
    "                                df.at[index, f'result_{loss_col}'] = 'loss'\n",
    "                                df.at[index, f'result_{loss_col}_value'] = price_var - entry_price\n",
    "                                break\n",
    "                    else:  # 'short'\n",
    "                        price_vars = [next_open, next_high, next_low, next_close]\n",
    "                        for price_var in price_vars:\n",
    "                            if price_var < target_price:\n",
    "                                df.at[index, f'out_day_{loss_col}'] = int(i)\n",
    "                                df.at[index, f'result_{loss_col}'] = 'profit'\n",
    "                                df.at[index, f'result_{loss_col}_value'] = entry_price - price_var\n",
    "                                break\n",
    "                            elif price_var > stop_loss_val:\n",
    "                                df.at[index, f'out_day_{loss_col}'] = int(i)\n",
    "                                df.at[index, f'result_{loss_col}'] = 'loss'\n",
    "                                df.at[index, f'result_{loss_col}_value'] = entry_price - price_var\n",
    "                                break\n",
    "                    \n",
    "                    if not np.isnan(df.at[index, f'out_day_{loss_col}']):\n",
    "                        break\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def summarize_results(df):\n",
    "        \"\"\"\n",
    "        Summarize profit and loss results for different stop loss levels.\n",
    "\n",
    "        This function calculates the total profit and loss for each stop loss level present\n",
    "        in the DataFrame. The stop loss levels are identified dynamically based on column names\n",
    "        that follow the pattern 'result_sl_X.Y'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame containing the trade results. The DataFrame must\n",
    "                            have columns with names in the format 'result_sl_X.Y' and\n",
    "                            'result_sl_X.Y_value', where X.Y represents the stop loss level.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with columns 'Level', 'Profit', and 'Loss', summarizing\n",
    "                        the total profit and loss for each stop loss level.\n",
    "        \"\"\"\n",
    "        summary_df = pd.DataFrame(columns=['Risk Reward Ratio', 'Profit', 'Loss', 'Net', 'Profits Count', 'Losses Count', 'Success Rate'])\n",
    "        \n",
    "        levels = set()\n",
    "        for col in df.columns:\n",
    "            match = re.match(r'result_sl_(\\d+\\.\\d+)', col)\n",
    "            if match:\n",
    "                levels.add(match.group(1))\n",
    "        \n",
    "        levels = sorted(levels, key=lambda x: float(x))        \n",
    "        summary_list = []\n",
    "        for level in levels:\n",
    "            results_col = f'result_sl_{level}'\n",
    "            values_col = f'result_sl_{level}_value'\n",
    "            \n",
    "            if results_col in df.columns and values_col in df.columns:\n",
    "                df[values_col] = pd.to_numeric(df[values_col], errors='coerce')\n",
    "                \n",
    "                profits_series = df[df[values_col] > 0][values_col]\n",
    "                losses_series = df[df[values_col] < 0][values_col]\n",
    "                \n",
    "                profits = profits_series.sum()\n",
    "                profits_count = profits_series.count()\n",
    "                \n",
    "                losses = losses_series.sum()\n",
    "                losses_count = losses_series.count()\n",
    "                \n",
    "                total_trades = profits_count + losses_count\n",
    "                success_rate = profits_count / total_trades if total_trades > 0 else 0\n",
    "                \n",
    "                summary_list.append({\n",
    "                    'Risk Reward Ratio': level,\n",
    "                    'Profit': profits,\n",
    "                    'Loss': losses,\n",
    "                    'Net': profits + losses,\n",
    "                    'Profits Count': profits_count,\n",
    "                    'Losses Count': losses_count,\n",
    "                    'Success Rate': success_rate\n",
    "                })\n",
    "        \n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame(summary_list)], ignore_index=True)\n",
    "        \n",
    "        return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\guitz\\\\OneDrive\\\\Área de Trabalho\\\\pyquant\\\\pyquant\\\\noteboks\\\\prices_volume.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Error loading market data: [Errno 2] No such file or directory: 'c:\\\\\\\\Users\\\\\\\\guitz\\\\\\\\OneDrive\\\\\\\\Área de Trabalho\\\\\\\\pyquant\\\\\\\\pyquant\\\\\\\\noteboks\\\\\\\\prices_volume.csv'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ticker = CandleFit(market_data='prices_volume.csv', timeframe='M5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ticker.summarize_results(backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.candlestick_chart(key='is_hammer', plot_type='pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.features.is_hammer.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
